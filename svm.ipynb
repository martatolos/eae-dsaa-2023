{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/martatolos/eae-dsaa-2025/blob/main/svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Support Vector Machines (SVMs) using Python\n",
    "\n",
    "Goal of the session: At the end of this tutorial, you will understand the basics of SVM models and how to apply them using `scikit-learn`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## SVM: Recap theory\n",
    "\n",
    "**Describe in your own words: what is a support vector machine (SVM) and how does it work?**\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>üí° Show solution</summary>\n",
    "  <ul>\n",
    "    <li>Set of supervised learning methods used for classification (and sometimes for regression and outliers detection).</li>\n",
    "    <li>Core idea: It finds the best boundary (hyperplane) that separates data points of different classes with the maximum margin.</li>\n",
    "    <li>Margin: The distance between the hyperplane and the nearest data points of each class. SVM tries to maximize this margin for better generalization.</li>\n",
    "    <li>Works linearly in basic form but can handle non-linear separation using the kernel trick (e.g., RBF, polynomial kernels) to project data into higher dimensions.</li>\n",
    " </ul>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Pros and Cons\n",
    "\n",
    "**Strengths of SVMs:**\n",
    "- Effective in high-dimensional spaces (i.e., with many features, like text data) - even effective approach even if the number of features is (much) larger than the number of samples\n",
    "- Memory efficient - uses only a subset of training data (support vectors).\n",
    "- Non-linearity - can handle non-linear separation using the kernel trick (e.g., RBF, polynomial kernels) to project data into higher dimensions.\n",
    "- Versatile - can be used with different kernel functions for linear and non-linear classification\n",
    "- Robust to overfitting - especially in high-dimensional settings with proper regularization\n",
    "\n",
    "**Weaknesses of SVMs**\n",
    "- Not suitable for large datasets - training time and memory usage scale poorly with number of samples.\n",
    "- Performance drops with noisy data and overlapping classes.\n",
    "- Limited interpretability - unlike decision trees or linear models, SVMs can be hard to explain.\n",
    "- No direct probability estimates - requires extra calibration if probabilities are needed.\n",
    "- Hard to tune ‚Äî choosing the right kernel and hyperparameters (C, gamma) can be tricky."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## SVMs in Python using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Prerequisite\n",
    "\n",
    "Before we begin, we have to install the necessary python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==2.0.2 pandas==2.2.2 scikit-learn==1.6.1 seaborn==0.13.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run general imports\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Reading iris dataset\n",
    "\n",
    "For illustrating SVMs in `scikit-learn` we leverage the iris dataset from last week's tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "# Load the data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# We define a Dataframe (tabular structure) with the predictor variables\n",
    "# and on the other hand a separated vector with the response variable\n",
    "iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "y = iris.target  # Target variable\n",
    "\n",
    "display(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Let's visualize the features of the dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# For the purpose of plotting the graphic we make a copy of the data frame\n",
    "# and add our target column for better visualization\n",
    "df_label = iris_df.copy()\n",
    "species_dict = {0: \"setosa\", 1: \"versicolor\", 2: \"virginica\"}\n",
    "df_label[\"species\"] = pd.Series(y).map(species_dict)\n",
    "\n",
    "sns.pairplot(\n",
    "    df_label,\n",
    "    hue=\"species\",  # Color data points differently based on their value in column  \"species\"\n",
    "    plot_kws={\"alpha\": 0.3},  # Transparency prevents under-representation of overlapping points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Building train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_df, y, test_size=0.3, random_state=70, stratify=y)\n",
    "\n",
    "# Python f-strings\n",
    "print(f\"Train dataset size {len(X_train)} / test dataset size {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### SVM implementations in scikit-learn\n",
    "\n",
    "The `scikit-learn` library offers multiple implementations for SVMs (in package `sklearn.svm`) focused on different use-cases and scenarios:\n",
    "\n",
    "| Class       | Task           | Kernel Support     | Scales Well? |\n",
    "| ----------- | -------------- | ------------------ | ------------ |\n",
    "| `SVC`       | Classification | Yes (nonlinear OK) | ‚ùå Medium     |\n",
    "| `NuSVC`     | Classification | Yes                | ‚ùå Medium     |\n",
    "| `LinearSVC` | Classification | Only Linear        | ‚úÖ Large      |\n",
    "| `SVR`       | Regression     | Yes                | ‚ùå Medium     |\n",
    "| `NuSVR`     | Regression     | Yes                | ‚ùå Medium     |\n",
    "| `LinearSVR` | Regression     | Only Linear        | ‚úÖ Large      |\n",
    "\n",
    "In our tutorial today, we'll focus on the following two implementations:\n",
    "\n",
    "1. `sklearn.svm.SVC` ‚Äî Support Vector Classification\n",
    "- Standard SVM for classification tasks.\n",
    "- Supports linear, polynomial, RBF, and sigmoid kernels.\n",
    "- Can use the kernel trick.\n",
    "- Suitable for small to medium datasets.\n",
    "\n",
    "2. `sklearn.svm.LinearSVC`: Linear Support Vector Classification\n",
    "- Optimized for large datasets with a linear kernel only.\n",
    "- Much faster than `SVC(kernel=\"linear\")`.\n",
    "- However - does not support the kernel trick.\n",
    "\n",
    "Please refer to the [documentation page](https://scikit-learn.org/stable/modules/svm.html) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### SVM training\n",
    "\n",
    "Let's train a first SVM on the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Linear SVM classifier\n",
    "clf_svm = svm.SVC(kernel=\"linear\")\n",
    "clf_svm.fit(X_train, y_train)\n",
    "clf_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Check the performance of the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Check the overall accuracy of the model on the validation set\n",
    "y_pred = clf_svm.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 2. Check the performance per class\n",
    "report = classification_report(y_test, y_pred, target_names=[\"setosa\", \"versicolor\", \"virginica\"])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 3. Check the confusion matrix to better understand the errors\n",
    "svm_conf_mat = confusion_matrix(y_test, y_pred)\n",
    "svm_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "\n",
    "The `SVC` has three important hyperparameters:\n",
    "\n",
    "1. `C` (default=`1.0`)\n",
    "- Controls the trade-off between a smooth decision boundary and classifying training points correctly\n",
    "- Low C ‚Üí smoother boundary, more regularization (however might underfit)\n",
    "- High C ‚Üí less regularization, fits training data more tightly (risk of overfitting)\n",
    "\n",
    "2. `kernel` (default=`rbf`)\n",
    "- Specifies the type of kernel used to transform the data:\n",
    "- `linear` ‚Äì linear decision boundary\n",
    "- `poly` ‚Äì polynomial kernel\n",
    "- `rbf` ‚Äì radial basis function (Gaussian), usually a good default\n",
    "\n",
    "3. `gamma` (default=`scale`)\n",
    "- Controls how far the influence of a single training example reaches.\n",
    "- Only available when using 'rbf', 'poly', 'sigmoid' kernel\n",
    "- Can be `scale`, `auto` or a fixed number\n",
    "- `auto`: 1 / n_features\n",
    "- `scale`: 1 / (n_features * Var(X))\n",
    "- Low gamma ‚Üí ‚Äòfar‚Äô influence, smoother boundaries.\n",
    "- High gamma ‚Üí ‚Äòclose‚Äô influence, tighter fit, potential overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=71, stratify=y_train)\n",
    "\n",
    "# Python f-strings\n",
    "print(f\"Train dataset size {len(X_train)} / val dataset size {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM classifier with RBF kernel\n",
    "clf_svm_rbf = svm.SVC(kernel=\"rbf\", C=1.0, gamma=0.1)\n",
    "clf_svm_rbf.fit(X_train, y_train)\n",
    "clf_svm_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test set\n",
    "y_pred = clf_svm_rbf.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "**Exercise: Investigate the influence of different kernels and hyper-parameters settings on the performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here ...\n",
    "\n",
    "# 1. Define hyperparameters and instantiate a SVM\n",
    "\n",
    "# 2. Train a SVM classifier on the training data set\n",
    "\n",
    "# 3. Validate the performance on the validation set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization\n",
    "\n",
    "`sklearn` offers utilities to run hyperparameter optimization using (for example) `GridSearchCV` or `RandomizedSearchCV`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the parameter values we want to explore\n",
    "parameter_values = {\"C\": [0.1, 1, 10, 100], \"gamma\": [0.001, 0.01, 0.1, 1], \"kernel\": [\"linear\", \"rbf\"]}\n",
    "\n",
    "# Instantiate grid search util\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=SVC(),  # Classifier to be optimized\n",
    "    param_grid=parameter_values,  # Parameter values to explore\n",
    "    cv=5,  # Number of cross-validations to be performed\n",
    "    scoring=\"accuracy\",  # Scoring function to rate the different parameter combinations\n",
    "    n_jobs=-1,  # Number of parallel execution\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Show best results\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best classifier to predict target on new instance\n",
    "y_pred = grid_search.predict(X_val)\n",
    "accuracy_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also access the best model directly\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the complete result overview of all configurations\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the result by test score (rank)\n",
    "display(results.sort_values(\"rank_test_score\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Visualize the decision boundaries\n",
    "\n",
    "For illustration purposes, we will reload the data and take only the first two features of the iris data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reload data set\n",
    "iris = datasets.load_iris()\n",
    "X = pd.DataFrame(iris.data[:, :2], columns=[iris.feature_names[0], iris.feature_names[1]])  # first 2 features\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a figure highlight the data points and their classes\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(121)\n",
    "plt.scatter(\n",
    "    x=X[iris.feature_names[0]], y=X[iris.feature_names[1]], c=y, cmap=plt.cm.Set1\n",
    ")  # Parameter c controls the highlight\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "plt.title(\"Iris dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "Re-train an SVM model based only on the two features selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "# Train the model using a linear kernel\n",
    "svc_clf = svm.SVC(kernel=\"linear\", C=1, gamma=1)  # C and gamma are hyper-parameters\n",
    "svc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "Now let's plot the decision boundary for the linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Create a figure using matplot lib\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Use a utility class from scikit-learn to print the decision boundaries\n",
    "disp = DecisionBoundaryDisplay.from_estimator(\n",
    "    svc_clf,\n",
    "    X,\n",
    "    response_method=\"predict\",\n",
    "    cmap=plt.cm.coolwarm,\n",
    "    alpha=0.8,\n",
    "    ax=ax,\n",
    "    xlabel=iris.feature_names[0],\n",
    "    ylabel=iris.feature_names[1],\n",
    ")\n",
    "\n",
    "# Plot the data points\n",
    "ax.scatter(X[iris.feature_names[0]], X[iris.feature_names[1]], c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "Now let's compare different models together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models that we want to inspect and their configurations\n",
    "models = [\n",
    "    svm.SVC(kernel=\"linear\", C=1),\n",
    "    svm.LinearSVC(C=1, max_iter=10000),\n",
    "    svm.SVC(kernel=\"rbf\", gamma=0.7, C=1),\n",
    "    svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=1),\n",
    "]\n",
    "\n",
    "# Fit all the models\n",
    "models = [clf.fit(X_train, y_train) for clf in models]\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "Now let's compare their decision boundaries graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Titles for the plots\n",
    "titles = (\n",
    "    \"SVC with linear kernel\",\n",
    "    \"LinearSVC (linear kernel)\",\n",
    "    \"SVC with RBF kernel\",\n",
    "    \"SVC with polynomial (degree 3) kernel\",\n",
    ")\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten(), strict=False):\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        X,\n",
    "        response_method=\"predict\",\n",
    "        cmap=plt.cm.coolwarm,\n",
    "        alpha=0.8,\n",
    "        ax=ax,\n",
    "        xlabel=iris.feature_names[0],\n",
    "        ylabel=iris.feature_names[1],\n",
    "    )\n",
    "    ax.scatter(X[iris.feature_names[0]], X[iris.feature_names[1]], c=y, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "**Exercise: Investigate the changes in the decision boundary if changing hyperparameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Implementation hints\n",
    "\n",
    "**Feature scaling**\n",
    "\n",
    "The input features of an SVM should always be scaled as SVMs are distance-based models, i.e, they rely heavily on dot products and Euclidean distances (especially when using kernels).\n",
    "\n",
    "- If features are on different scales, one can dominate the others, leading to poor decision boundaries.\n",
    "- Unscaled features distort the kernel: The RBF kernel is sensitive to feature magnitude. Large-scale features can skew similarity calculations.\n",
    "- Optimization becomes harder: Feature imbalance can lead to slow convergence or convergence failure in the underlying solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the processing pipeline\n",
    "pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"svc\", SVC(kernel=\"linear\"))])\n",
    "\n",
    "# Train the classifier using the pipeline\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothing changes for the predict method\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Pipelines can also be used when performing grid search for the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"svc\", SVC())])\n",
    "\n",
    "# For the parameter specification we have to put the name of the component\n",
    "# before the parameter name (e.g., svc__C for parameter 'C' of component 'svc')\n",
    "param_grid = {\"svc__C\": [0.1, 1, 10, 100], \"svc__gamma\": [0.001, 0.01, 0.1, 1], \"svc__kernel\": [\"rbf\"]}\n",
    "\n",
    "# ... the remainder of the code stays the same\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring=\"accuracy\")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "grid.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "### Exercise: classify hand writings\n",
    "\n",
    "In this exercise, we'll use the MNIST dataset,  a classic benchmark dataset in machine learning and computer vision. It contains:\n",
    "\n",
    "- 70,000 grayscale images of handwritten digits (0 to 9)\n",
    "- Each image is 8x8 / 28√ó28 pixels\n",
    "- Labels correspond to the digit shown in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset (this is actually the 8x8 version; for full 28x28 see below)\n",
    "from sklearn import datasets\n",
    "\n",
    "size = 8\n",
    "digits = datasets.load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# ------------------\n",
    "# from sklearn.datasets import fetch_openml\n",
    "# size = 28\n",
    "# digits = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "# X, y = digits.data / 255.0, digits.target.astype(int)\n",
    "\n",
    "# We only use 2.5k of the points (otherwise training will take too long)\n",
    "# X = X[:2500]\n",
    "# y = y[:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at our features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and target\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "The feature values are difficult to interpret. Let's visualize the numbers instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Number of images to display\n",
    "num_images = 16\n",
    "rows, cols = 4, 4  # 4x4 grid\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(6, 6))\n",
    "fig.suptitle(\"MNIST Digits\", fontsize=16)\n",
    "\n",
    "for i in range(num_images):\n",
    "    ax = axes[i // cols, i % cols]\n",
    "    ax.imshow(X[i].reshape(size, size), cmap=\"gray\")\n",
    "    ax.set_title(f\"Label: {y[i]}\", fontsize=8)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "**Now it's your turn:**\n",
    "- Split the data into a train, validation and test set\n",
    "- Train a classifier of your choice (e.g. decision tree, logistic regression, SVM)\n",
    "- Evaluate the performance of the classifier\n",
    "- Analyze the prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You code here ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
