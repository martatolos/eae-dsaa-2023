{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/martatolos/eae-dsaa-2025/blob/main/nlp_tasks_with_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RphG7RUu0JHB"
   },
   "source": [
    "# Solving Natural Language Processing tasks with GPT\n",
    "\n",
    "> Goal of the session:\n",
    ">\n",
    "> - Get familiarity with the most common NLP tasks using an LLM.\n",
    ">\n",
    ">Scope of the session\n",
    ">\n",
    "> - Use LLMs for common NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen, LLMs are capable of carrying out downstream NLP tasks. Although they have not been fine-tuned for solving certain specific tasks, they perform greatly on some of them.\n",
    "\n",
    "You can use:\n",
    "  - [OpenAI API](https://platform.openai.com)\n",
    "  - [UI of OpenAI ChatGPT](https://chatgpt.com)\n",
    "\n",
    "> [!Note]\n",
    "> If you will use the UI, please, use a text editor to create your prompts. Once ready, you can copy-paste them in the UI. It will make the process easier for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLrJDGahAT2-"
   },
   "source": [
    "## 1. Setup\n",
    "\n",
    "**Only for those ones that will carry out this activity using the OpenAI API.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies\n",
    "\n",
    "- ``ipython``\n",
    "- ``openai`` 1.75.0\n",
    "- ``python-dotenv``\n",
    "- ``spacy`` 3.8.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgoXSIW_zs0x",
    "outputId": "77d1f3d5-26a9-406d-df70-d9b725d269e4"
   },
   "outputs": [],
   "source": [
    "%pip install ipython openai==1.75.0 python-dotenv spacy==3.8.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dotenv\n",
    "import spacy\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Key\n",
    "\n",
    "Add your OpenAI API key in the cell below or create a `.env` file in the same directory as this notebook with the following content:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "```\n",
    "\n",
    "> [!Warning]\n",
    "> Make sure you do not save or commit the file without removing your API key. If that happens, reset the key so that it is not compromised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_ai_key = None  # Add your OpenAI API key here\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", open_ai_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "\n",
    "Next, we will create a function that we will use in today's activity and in the next NLP lecture as well. We will use [chat completions endpoint](https://platform.openai.com/docs/guides/text-generation/chat-completions-api).\n",
    "\n",
    "Also most LLMs use markdown format to in their output. We will use ``render_markdown`` function to show the outputs we get in a more readable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt: str, model_name: str = \"gpt-4o-mini\") -> str:\n",
    "    \"\"\"Get the completion from OpenAI API.\n",
    "\n",
    "    :param prompt: Prompt to be sent to the model.\n",
    "    :param model_name: Name of the model which will be used.\n",
    "        Check https://platform.openai.com/docs/models to get an updated list.\n",
    "        Defaults to \"gpt-4o-mini\"\n",
    "    :return: Completion from the model.\n",
    "    \"\"\"\n",
    "    return OpenAI().responses.create(model=model_name, input=prompt).output[0].content[0].text\n",
    "\n",
    "\n",
    "def render_markdown(text: str) -> None:\n",
    "    \"\"\"Render the text as markdown.\n",
    "\n",
    "    :param text: Text to be rendered.\n",
    "    \"\"\"\n",
    "    display(Markdown(text))\n",
    "\n",
    "\n",
    "def show_completion(prompt: str, model_name: str = \"gpt-4o-mini\") -> None:\n",
    "    \"\"\"Get the completion from OpenAI API and render it as markdown.\n",
    "\n",
    "    :param prompt: Prompt to be sent to the model.\n",
    "    :param model_name: Name of the model which will be used.\n",
    "        Check https://platform.openai.com/docs/models to get an updated list.\n",
    "        Defaults to \"gpt-4o-mini\"\n",
    "    \"\"\"\n",
    "    completion = get_completion(prompt, model_name)\n",
    "    render_markdown(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "nf9YFmaO3UyF",
    "outputId": "074c8c2f-298d-4975-e4bc-184a65d45045"
   },
   "outputs": [],
   "source": [
    "prompt = \"Tell me a joke\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFc4UxO23ZE0"
   },
   "source": [
    "## 2. Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4dZOl0Z3Xtv"
   },
   "outputs": [],
   "source": [
    "prod_review = \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\\n",
    "super cute, and its face has a friendly look. It's \\\n",
    "a bit small for what I paid though. I think there \\\n",
    "might be other options that are bigger for the \\\n",
    "same price. It arrived a day earlier than expected, \\\n",
    "so I got to play with it myself before I gave it \\\n",
    "to her.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yLY2oDK3vuf"
   },
   "source": [
    "### Summarize with a word/sentence/character limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_QRQmVU3uoi",
    "outputId": "7ce98edd-1633-4341-f78f-0a1e2ac58bf7"
   },
   "outputs": [],
   "source": [
    "# with word limit\n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 30.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "render_markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Cmmh75y4kKi"
   },
   "source": [
    "Let's check whether the model generated an answer with the word limits specified in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iki4rgpk38VU",
    "outputId": "7c5e94e8-9106-4de2-9574-b595fd0d0224"
   },
   "outputs": [],
   "source": [
    "n_words = len(response.split())\n",
    "print(f\"The response has {n_words} words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the model can adhere to the number of words we ask for, the model uses tokens internally.\n",
    "\n",
    "Here you can see how the response is split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(response)\n",
    "tokens = list(doc)\n",
    "for i, token in enumerate(tokens):\n",
    "    print(f\"{i}\\t'{token}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vdCtzFM6E4n",
    "outputId": "e3a6cbd2-a0c2-4f52-86c6-be29dc378949"
   },
   "outputs": [],
   "source": [
    "# with character limit\n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 100 characters.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "render_markdown(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnKa76vr6WC7"
   },
   "source": [
    "Let's check whether the model generated an answer with the character limits specified in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dfHDmLc6QmC",
    "outputId": "9b497dc2-7438-410c-fe44-481fca21108b"
   },
   "outputs": [],
   "source": [
    "for i, character in enumerate(response):\n",
    "    print(f\"{i}\\t'{character}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Q--Tkb94Ru8",
    "outputId": "85875773-a3f4-41ae-d11b-cb183aab6280"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in one single sentence.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feNdQHnh6sO3"
   },
   "source": [
    "### Summarize focusing on specific topics of the text\n",
    "\n",
    "#### Focus on shipping and delivery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xc6Cw4IW6Cis",
    "outputId": "db70c114-ce43-4392-996d-a524d44149a1"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site to give feedback to the \\\n",
    "Shipping deparmtment.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that mention shipping and delivery of the product.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glbGazEQ6-gy"
   },
   "source": [
    "#### Focus on price and value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9sI7XOe7NVB",
    "outputId": "18d64978-b418-4afe-d61d-a6196d1d5bef"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site to give feedback to the \\\n",
    "pricing deparmtment, responsible for determining the \\\n",
    "price of the product.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that are relevant to the price and perceived value.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIR0tVUq7XZp"
   },
   "source": [
    "### Extract information instead of summarizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwoQrmpS7QDe",
    "outputId": "c7c7188b-ed66-4b52-c5f2-b5fa552b09e1"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to extract relevant information from \\\n",
    "a product review from an ecommerce site to give \\\n",
    "feedback to the Shipping department.\n",
    "\n",
    "From the review below, delimited by triple quotes \\\n",
    "extract the information relevant to shipping and \\\n",
    "delivery. Limit to 30 words.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEVLZS6p72WP"
   },
   "source": [
    "### Summarize multiple product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PReBcYph7hJO"
   },
   "outputs": [],
   "source": [
    "review_1 = prod_review\n",
    "\n",
    "# review for a standing lamp\n",
    "review_2 = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one \\\n",
    "had additional storage and not too high of a price \\\n",
    "point. Got it fast - arrived in 2 days. The string \\\n",
    "to the lamp broke during the transit and the company \\\n",
    "happily sent over a new one. Came within a few days \\\n",
    "as well. It was easy to put together. Then I had a \\\n",
    "missing part, so I contacted their support and they \\\n",
    "very quickly got me the missing piece! Seems to me \\\n",
    "to be a great company that cares about their customers \\\n",
    "and products.\n",
    "\"\"\"\n",
    "\n",
    "# review for an electric toothbrush\n",
    "review_3 = \"\"\"\n",
    "My dental hygienist recommended an electric toothbrush, \\\n",
    "which is why I got this. The battery life seems to be \\\n",
    "pretty impressive so far. After initial charging and \\\n",
    "leaving the charger plugged in for the first week to \\\n",
    "condition the battery, I've unplugged the charger and \\\n",
    "been using it for twice daily brushing for the last \\\n",
    "3 weeks all on the same charge. But the toothbrush head \\\n",
    "is too small. I've seen baby toothbrushes bigger than \\\n",
    "this one. I wish the head was bigger with different \\\n",
    "length bristles to get between teeth better because \\\n",
    "this one doesn't.  Overall if you can get this one \\\n",
    "around the $50 mark, it's a good deal. The manufactuer's \\\n",
    "replacements heads are pretty expensive, but you can \\\n",
    "get generic ones that're more reasonably priced. This \\\n",
    "toothbrush makes me feel like I've been to the dentist \\\n",
    "every day. My teeth feel sparkly clean!\n",
    "\"\"\"\n",
    "\n",
    "# review for a blender\n",
    "review_4 = \"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesn't look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "plan to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ice, rice, etc. in the \\\n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruits and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\\n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\\n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\"\n",
    "\n",
    "reviews = [review_1, review_2, review_3, review_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-u__VC7V7-Ym",
    "outputId": "ecf2a2ba-87f9-4ada-d299-48f67ba6471e"
   },
   "outputs": [],
   "source": [
    "for i, review in enumerate(reviews, 1):\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to generate a short summary of a product \\\n",
    "    review from an ecommerce site.\n",
    "\n",
    "    Summarize the review below, delimited by triple \\\n",
    "    backticks in at most 20 words.\n",
    "\n",
    "    Review: ```{review}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    render_markdown(f\"## Review {i}\\n{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxwsi-9g8JGI"
   },
   "source": [
    "### Time to practice on your own (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODE5yIG38dLQ"
   },
   "source": [
    "## 3. Text classification\n",
    "\n",
    "Examples:\n",
    "\n",
    "This product is great - SENTIMENT POSITIVE\n",
    "\n",
    "I would not buy this product again, it is useless - SENTIMENT NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4TlEZK_J8ERB"
   },
   "outputs": [],
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBWfTmMp9ORK"
   },
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HC8i4GtJ9Jft",
    "outputId": "1c3db8e5-6d1b-4bf2-d0c8-1bc73fc09fcf"
   },
   "outputs": [],
   "source": [
    "# sentiment analysis verbose\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review,\n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZbVvVii9UZT",
    "outputId": "38084bf6-4c18-4966-91ef-4cb7d445ec72"
   },
   "outputs": [],
   "source": [
    "# sentiment analysis just label\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review,\n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zw4Zd3QW9hGq"
   },
   "source": [
    "### Emotion detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xK5HW9yV9YS_",
    "outputId": "7cce6f1a-291b-4227-b51a-cc3805519cf2"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbEYHE5U9uDp"
   },
   "source": [
    "### Anger detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8ZH_Y279msV",
    "outputId": "04ecc57c-23d3-4dbf-e1aa-4f12f1a8f67b"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkyWozv295Lk"
   },
   "source": [
    "### Extract entities\n",
    "\n",
    "Scope:\n",
    "\n",
    "- Extraction of product names and company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkS0nf2e9zn3",
    "outputId": "6aa43a9e-a2e2-4e1e-9acd-9addce099466"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRm3sFns-L4p"
   },
   "source": [
    "### Solving multiple tasks at once\n",
    "\n",
    "Scope:\n",
    "\n",
    "- Sentiment analysis\n",
    "- Anger detection\n",
    "- Extraction of entities: product and company names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8O8ezx04-D0S",
    "outputId": "bf68532a-ff72-4fa1-9103-a2efb747c77a"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7I98rHb-mNN"
   },
   "source": [
    "### Topic detection (open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f634YFOT-p73"
   },
   "outputs": [],
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government,\n",
    "public sector employees were asked to rate their level\n",
    "of satisfaction with the department they work at.\n",
    "The results revealed that NASA was the most popular\n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings,\n",
    "stating, \"I'm not surprised that NASA came out on top.\n",
    "It's a great place to work with amazing people and\n",
    "incredible opportunities. I'm proud to be a part of\n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team,\n",
    "with Director Tom Johnson stating, \"We are thrilled to\n",
    "hear that our employees are satisfied with their work at NASA.\n",
    "We have a talented and dedicated team who work tirelessly\n",
    "to achieve our goals, and it's fantastic to see that their\n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the\n",
    "Social Security Administration had the lowest satisfaction\n",
    "rating, with only 45% of employees indicating they were\n",
    "satisfied with their job. The government has pledged to\n",
    "address the concerns raised by employees in the survey and\n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBAsH8c5-tDN",
    "outputId": "103bdefe-0801-483f-dca7-77d27ca93f61"
   },
   "outputs": [],
   "source": [
    "# infer 5 topics\n",
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long.\n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tUr85DC_Ejs"
   },
   "source": [
    "### Topic detection from a pre-defined list of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOTXckhI-1Dy"
   },
   "outputs": [],
   "source": [
    "topic_list = [\n",
    "    \"nasa\",\n",
    "    \"local government\",\n",
    "    \"engineering\",\n",
    "    \"employee satisfaction\",\n",
    "    \"federal government\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyEoLUI6_UyO",
    "outputId": "999c3ded-dcd0-4191-86ef-87bc540a54f3"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic.\\\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiDDFukA_9Dv"
   },
   "source": [
    "### Time to practice on your own (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23b86KB3DAGe"
   },
   "source": [
    "## 4. Translation\n",
    "\n",
    "ChatGPT has been trained with multilingual data. For this reason, this model is capable if translating text as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJMPKPvz_1pO"
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Barcelona is a city on the northeastern coast of Spain. \\\n",
    "It is the capital and largest city of the autonomous community of Catalonia, \\\n",
    "as well as the second-most populous municipality of Spain. \\\n",
    "With a population of 1.6 million within city limits, \\\n",
    "its urban area extends to numerous neighbouring municipalities within the province \\\n",
    "of Barcelona and is home to around 4.8 million people, \\\n",
    "making it the fifth most populous urban area in the European Union after Paris, \\\n",
    "the Ruhr area, Madrid and Milan. \\\n",
    "It is one of the largest metropolises on the Mediterranean Sea, \\\n",
    "located on the coast between the mouths of the rivers Llobregat and Besòs, \\\n",
    "bounded to the west by the Serra de Collserola mountain range.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZySxcDetEVDp",
    "outputId": "222a6835-185a-4c33-9a1d-4357921ad565"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text delimited by tags <text> to Spanish. \\\n",
    "\n",
    "<text>{text}<text>\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXXtutSqEvpn"
   },
   "source": [
    "### Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HwZsP2mEoFC",
    "outputId": "c0396988-376b-4ab6-d874-bcbf4b287144"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Tell me the language of the following text delimited by tags <text>. \\\n",
    "\n",
    "<text>\n",
    "Barcelone est une ville située sur la côte nord-est de l'Espagne. \\\n",
    "C'est la capitale et la plus grande ville de la communauté autonome de Catalogne, \\\n",
    "ainsi que la deuxième municipalité la plus peuplée d'Espagne. \\\n",
    "Avec une population de 1,6 million d'habitants dans les limites de la ville, \\\n",
    "son aire urbaine s'étend à de nombreuses municipalités voisines de la province \\\n",
    "de Barcelone et abrite environ 4,8 millions de personnes, \\\n",
    "ce qui en fait la cinquième aire urbaine la plus peuplée de l'Union européenne \\\n",
    "après Paris, la région de la Ruhr, Madrid et Milan. \\\n",
    "C'est l'une des plus grandes métropoles de la mer Méditerranée, \\\n",
    "située sur la côte entre les embouchures des rivières Llobregat et Besòs, \\\n",
    "bordée à l'ouest par la chaîne de montagnes de la Serra de Collserola.\n",
    "<text>\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IlFSeGBFilk"
   },
   "source": [
    "### Multilingual translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4uzHFucFVn4",
    "outputId": "66995351-ce66-4f4a-ff74-1c59814c6ffa"
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text delimited by tags <text> to Spanish and French. \\\n",
    "\n",
    "<text>{text}<text>\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pL5EluMyGZ8W"
   },
   "source": [
    "### Language detection + multilingual translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9QM2acIsGeod"
   },
   "outputs": [],
   "source": [
    "user_messages = [\n",
    "    \"La performance du système est plus lente que d'habitude.\",  # System performance is slower than normal\n",
    "    \"Mi monitor tiene píxeles que no se iluminan.\",  # My monitor has pixels that are not lighting\n",
    "    \"Il mio mouse non funziona\",  # My mouse is not working\n",
    "    \"Mój klawisz Ctrl jest zepsuty\",  # My keyboard has a broken control key\n",
    "    \"我的屏幕在闪烁\",  # My screen is flashing\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySqWvpzYGfph",
    "outputId": "3699208f-1761-472d-e259-59d97bc8cc9c"
   },
   "outputs": [],
   "source": [
    "for issue in user_messages:\n",
    "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
    "    lang = get_completion(prompt)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Translate the following  text to English \\\n",
    "    and Korean: ```{issue}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    render_markdown(f\"**Original message** ({lang}): {issue}\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ECZ_wGmGrpn"
   },
   "source": [
    "### Adapt tone of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYuHubKnGie8",
    "outputId": "d68a2213-2d7f-4e64-878e-7d3dff071724"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following from slang to a business letter:\n",
    "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBLQ7pXdHTwz"
   },
   "source": [
    "### Spellcheck and grammar check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PB3BXnGcHF4J",
    "outputId": "0fa39821-25aa-4220-e645-e52fd23d5559"
   },
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
    "    \"Yolanda has her notebook.\",  # ok\n",
    "    \"Its going to be a long day. Does the car need it's oil changed?\",  # Homonyms\n",
    "    \"Their goes my freedom. There going to bring they're suitcases.\",  # Homonyms\n",
    "    \"Your going to need you're notebook.\",  # Homonyms\n",
    "    \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\",  # Homonyms\n",
    "    \"This phrase is to cherck chatGPT for speling abilitty\",  # spelling\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    prompt = f\"\"\"Proofread and correct the following text\n",
    "  and rewrite the corrected version. If you don't find\n",
    "  and errors, just say \"No errors found\". Don't use\n",
    "  any punctuation around the text:\n",
    "  ```{text}```\n",
    "\n",
    "  \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    render_markdown(f\"## Original text\\n{text}\\n## Corrected text\\n{response}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLzj2dgkJWdW"
   },
   "source": [
    "As you can see, answers generated are not highly accurate."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
