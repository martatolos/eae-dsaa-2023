{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/martatolos/eae-dsaa-2025/blob/main/nlp_tasks_with_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RphG7RUu0JHB"
   },
   "source": [
    "# Solving Natural Language Processing tasks with GPT\n",
    "\n",
    "> Goal of the session:\n",
    ">\n",
    "> - Get familiarity with the most common NLP tasks using an LLM.\n",
    ">\n",
    ">Scope of the session\n",
    ">\n",
    "> - Use LLMs for common NLP tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "As we have seen in the lecture, LLMs are capable of carrying out diverse downstream NLP tasks. Although they have not been fine-tuned for solving certain specific tasks, they perform greatly on some of them. For performing a certain NLP task we have to design a prompt consisting of instructions describing the specific task."
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLrJDGahAT2-"
   },
   "source": [
    "### 1. Setup\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "- ``ipython``\n",
    "- ``openai`` 1.75.0\n",
    "- ``python-dotenv``5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgoXSIW_zs0x",
    "outputId": "77d1f3d5-26a9-406d-df70-d9b725d269e4"
   },
   "source": "%pip install ipython openai==1.75.0 python-dotenv",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "\n",
    "First, let's perform import of classes and functions we'll use through out the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import dotenv\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup OpenAI API Key\n",
    "\n",
    "Add your OpenAI API key in the cell below or create a `.env` file in the same directory as this notebook with the following content:\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=your_openai_api_key\n",
    "```\n",
    "\n",
    "> [!Warning]\n",
    "> Make sure you do not save or commit the file without removing your API key. If that happens, reset the key so that it is not compromised."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "open_ai_key = None  # Add your OpenAI API key here\n",
    "dotenv.load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", open_ai_key)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions\n",
    "\n",
    "Next, we will create a function that we will use in today's activity. We will use [chat completions endpoint](https://platform.openai.com/docs/guides/text-generation/chat-completions-api). Also most LLMs use markdown format to in their output. We will use ``render_markdown`` function to show the outputs we get in a more readable format."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_completion(prompt: str, model_name: str = \"gpt-4.1-nano\") -> str:\n",
    "    \"\"\"Get the completion from OpenAI API.\n",
    "\n",
    "    :param prompt: Prompt to be sent to the model.\n",
    "    :param model_name: Name of the model which will be used.\n",
    "        Check https://platform.openai.com/docs/models to get an updated list.\n",
    "        Defaults to \"gpt-4.1-nano\"\n",
    "    :return: Completion from the model.\n",
    "    \"\"\"\n",
    "    client = OpenAI()\n",
    "    response = client.responses.create(\n",
    "        model=model_name,\n",
    "        input=prompt\n",
    "    )\n",
    "    # print(response)\n",
    "    return response.output[0].content[0].text\n",
    "\n",
    "\n",
    "def render_markdown(text: str) -> None:\n",
    "    \"\"\"Render the text as markdown.\n",
    "\n",
    "    :param text: Text to be rendered.\n",
    "    \"\"\"\n",
    "    display(Markdown(text))\n",
    "\n",
    "\n",
    "def show_completion(prompt: str, model_name: str = \"gpt-4.1-nano\") -> None:\n",
    "    \"\"\"Get the completion from OpenAI API and render it as markdown.\n",
    "\n",
    "    :param prompt: Prompt to be sent to the model.\n",
    "    :param model_name: Name of the model which will be used.\n",
    "        Check https://platform.openai.com/docs/models to get an updated list.\n",
    "        Defaults to \"gpt-4.1-nano\"\n",
    "    \"\"\"\n",
    "    completion = get_completion(prompt, model_name)\n",
    "    render_markdown(completion)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "nf9YFmaO3UyF",
    "outputId": "074c8c2f-298d-4975-e4bc-184a65d45045"
   },
   "source": [
    "prompt = \"Tell me a joke\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bFc4UxO23ZE0"
   },
   "source": [
    "## 2. Summarization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "N4dZOl0Z3Xtv"
   },
   "source": [
    "prod_review = \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\\n",
    "super cute, and its face has a friendly look. It's \\\n",
    "a bit small for what I paid though. I think there \\\n",
    "might be other options that are bigger for the \\\n",
    "same price. It arrived a day earlier than expected, \\\n",
    "so I got to play with it myself before I gave it \\\n",
    "to her.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yLY2oDK3vuf"
   },
   "source": [
    "### Summarize with a word/sentence/character limit"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_QRQmVU3uoi",
    "outputId": "7ce98edd-1633-4341-f78f-0a1e2ac58bf7"
   },
   "source": [
    "# Provide a summary with word limit\n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an e-commerce website.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 30 words.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "render_markdown(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Cmmh75y4kKi"
   },
   "source": [
    "Let's check whether the model generated an answer with the word limits specified in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iki4rgpk38VU",
    "outputId": "7c5e94e8-9106-4de2-9574-b595fd0d0224"
   },
   "source": [
    "n_words = len(response.split())\n",
    "print(f\"The response has {n_words} words.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Even if the model can adhere to the number of words we ask for, the model uses tokens internally. For this let's have a look at the generated response by uncommenting the print statement in the `get_completion` function and run this cell again:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "response = get_completion(prompt)\n",
    "render_markdown(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_vdCtzFM6E4n",
    "outputId": "e3a6cbd2-a0c2-4f52-86c6-be29dc378949"
   },
   "source": [
    "# with character limit\n",
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an e-commerce website.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 100 characters.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "render_markdown(response)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnKa76vr6WC7"
   },
   "source": "Let's check whether the model generated an answer with the character limits specified in the prompt."
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6dfHDmLc6QmC",
    "outputId": "9b497dc2-7438-410c-fe44-481fca21108b"
   },
   "source": [
    "for i, character in enumerate(response):\n",
    "    print(f\"{i}\\t'{character}'\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Give constraints on the number of sentences."
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Q--Tkb94Ru8",
    "outputId": "85875773-a3f4-41ae-d11b-cb183aab6280"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an e-commerce website.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in one single sentence.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feNdQHnh6sO3"
   },
   "source": [
    "### Summarize focusing on specific topics of the text\n",
    "\n",
    "#### Focus on shipping and delivery"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xc6Cw4IW6Cis",
    "outputId": "db70c114-ce43-4392-996d-a524d44149a1"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an e-commerce website to give feedback to the \\\n",
    "Shipping department.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that mention shipping and delivery of the product.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glbGazEQ6-gy"
   },
   "source": [
    "#### Focus on price and value"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F9sI7XOe7NVB",
    "outputId": "18d64978-b418-4afe-d61d-a6196d1d5bef"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an e-commerce site to give feedback to the \\\n",
    "pricing department, responsible for determining the \\\n",
    "price of the product.\n",
    "\n",
    "Summarize the review below, delimited by triple\n",
    "backticks, in at most 30 words, and focusing on any aspects \\\n",
    "that are relevant to the price and perceived value.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIR0tVUq7XZp"
   },
   "source": [
    "### Extract information instead of summarizing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwoQrmpS7QDe",
    "outputId": "c7c7188b-ed66-4b52-c5f2-b5fa552b09e1"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Your task is to extract relevant information from \\\n",
    "a product review from an e-commerce website to give \\\n",
    "feedback to the Shipping department.\n",
    "\n",
    "From the review below, delimited by triple quotes \\\n",
    "extract the information relevant to shipping and \\\n",
    "delivery. Limit to 30 words.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEVLZS6p72WP"
   },
   "source": [
    "### Summarize multiple product reviews"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PReBcYph7hJO"
   },
   "source": [
    "# review for a standing lamp\n",
    "review_1 = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one \\\n",
    "had additional storage and not too high of a price \\\n",
    "point. Got it fast - arrived in 2 days. The string \\\n",
    "to the lamp broke during the transit and the company \\\n",
    "happily sent over a new one. Came within a few days \\\n",
    "as well. It was easy to put together. Then I had a \\\n",
    "missing part, so I contacted their support and they \\\n",
    "very quickly got me the missing piece! Seems to me \\\n",
    "to be a great company that cares about their customers \\\n",
    "and products.\n",
    "\"\"\"\n",
    "\n",
    "# review for an electric toothbrush\n",
    "review_2 = \"\"\"\n",
    "My dental hygienist recommended an electric toothbrush, \\\n",
    "which is why I got this. The battery life seems to be \\\n",
    "pretty impressive so far. After initial charging and \\\n",
    "leaving the charger plugged in for the first week to \\\n",
    "condition the battery, I've unplugged the charger and \\\n",
    "been using it for twice daily brushing for the last \\\n",
    "3 weeks all on the same charge. But the toothbrush head \\\n",
    "is too small. I've seen baby toothbrushes bigger than \\\n",
    "this one. I wish the head was bigger with different \\\n",
    "length bristles to get between teeth better because \\\n",
    "this one doesn't.  Overall if you can get this one \\\n",
    "around the $50 mark, it's a good deal. The manufactuer's \\\n",
    "replacements heads are pretty expensive, but you can \\\n",
    "get generic ones that're more reasonably priced. This \\\n",
    "toothbrush makes me feel like I've been to the dentist \\\n",
    "every day. My teeth feel sparkly clean!\n",
    "\"\"\"\n",
    "\n",
    "# review for a blender\n",
    "review_3 = \"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesn't look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "plan to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ice, rice, etc. in the \\\n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruits and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\\n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\\n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\"\n",
    "\n",
    "reviews = [review_1, review_2, review_3]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-u__VC7V7-Ym",
    "outputId": "ecf2a2ba-87f9-4ada-d299-48f67ba6471e"
   },
   "source": [
    "for i, review in enumerate(reviews, 1):\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to generate a short summary of a product \\\n",
    "    review from an ecommerce site.\n",
    "\n",
    "    Summarize the review below, delimited by triple \\\n",
    "    backticks in at most 20 words.\n",
    "\n",
    "    Review: ```{review}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    render_markdown(f\"## Review {i}\\n{response}\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dxwsi-9g8JGI"
   },
   "source": "### Time to practice on your own"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "example_text = \"\"\"\n",
    "The Rise of Urban Green Spaces\n",
    "Urban green spaces‚Äîparks, gardens, green roofs, and community forests‚Äîhave become\n",
    "increasingly essential as cities grow denser and hotter. Historically, public parks\n",
    "emerged in the 19th century as a response to industrialization, providing city dwellers\n",
    "with cleaner air and recreational space. Over time, their role has expanded well beyond\n",
    "leisure.\n",
    "\n",
    "Today, green spaces are seen as crucial tools in combating climate change. Trees and\n",
    "vegetation reduce the urban heat island effect, absorb carbon dioxide, and improve\n",
    "stormwater management. Additionally, they support biodiversity by creating small but vital\n",
    "habitats for birds, insects, and other wildlife within cities.\n",
    "\n",
    "From a public health perspective, exposure to greenery has been linked to lower stress\n",
    "levels, improved mental health, and increased physical activity. Studies show that\n",
    "neighborhoods with accessible parks tend to have lower rates of obesity and better social\n",
    "cohesion.\n",
    "\n",
    "Technology has also enhanced how cities manage and design green spaces. Sensors monitor\n",
    "soil moisture, drones assist in forest health assessments, and data-driven models help\n",
    "urban planners optimize green coverage. However, there are challenges: gentrification can\n",
    "occur when new green projects drive up housing costs, often pushing out long-term residents.\n",
    "\n",
    "Ultimately, urban green spaces are no longer optional luxuries‚Äîthey are fundamental\n",
    "infrastructure for sustainable, livable cities. The ongoing challenge is to ensure these\n",
    "benefits are equitably distributed and resilient to future environmental pressures.\n",
    "\"\"\"\n",
    "\n",
    "# Investigate different lengths, styles, topics to focus"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODE5yIG38dLQ"
   },
   "source": [
    "## 3. Text classification\n",
    "\n",
    "Examples:\n",
    "\n",
    "This product is great - SENTIMENT POSITIVE\n",
    "\n",
    "I would not buy this product again, it is useless - SENTIMENT NEGATIVE"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4TlEZK_J8ERB"
   },
   "source": [
    "lamp_review = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one had \\\n",
    "additional storage and not too high of a price point. \\\n",
    "Got it fast.  The string to our lamp broke during the \\\n",
    "transit and the company happily sent over a new one. \\\n",
    "Came within a few days as well. It was easy to put \\\n",
    "together.  I had a missing part, so I contacted their \\\n",
    "support and they very quickly got me the missing piece! \\\n",
    "Lumina seems to me to be a great company that cares \\\n",
    "about their customers and products!!\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EBWfTmMp9ORK"
   },
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HC8i4GtJ9Jft",
    "outputId": "1c3db8e5-6d1b-4bf2-d0c8-1bc73fc09fcf"
   },
   "source": [
    "# sentiment analysis verbose\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review,\n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ZbVvVii9UZT",
    "outputId": "38084bf6-4c18-4966-91ef-4cb7d445ec72"
   },
   "source": [
    "# sentiment analysis just label\n",
    "prompt = f\"\"\"\n",
    "What is the sentiment of the following product review,\n",
    "which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "For complex classification tasks it can be valueable to add a few examples in the prompt. This is called **few-shot-prompting**."
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# sentiment analysis with few-shot examples label\n",
    "prompt = f\"\"\"\n",
    "Your are an assistant helping to classify user review into positive or negative.\n",
    "The following examples show the text (marked with TEXT:) and classification (marked \\\n",
    "with CLASS:):\n",
    "\n",
    "Example 1\n",
    "TEXT: Absolutely love this product! It‚Äôs well-made, easy to use, and exceeded my expectations. Definitely worth the price.\n",
    "CLASS: positive\n",
    "\n",
    "Example 2\n",
    "TEXT: Disappointed. It didn‚Äôt work as advertised and the build quality feels cheap. Wouldn‚Äôt buy again.\n",
    "CLASS: negative\n",
    "\n",
    "Example 3\n",
    "TEXT: This is a game-changer. Works flawlessly and looks great. I‚Äôve already recommended it to my friends.\n",
    "CLASS: positive\n",
    "\n",
    "Example 4:\n",
    "TEXT: It‚Äôs okay at best. Setup was confusing and performance is inconsistent. Not terrible, but not great either.\n",
    "CLASS: negative\n",
    "\n",
    "Classify the text which is delimited with triple backticks?\n",
    "\n",
    "Give your answer as a single word, either \"positive\" \\\n",
    "or \"negative\".\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zw4Zd3QW9hGq"
   },
   "source": [
    "### Emotion detection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xK5HW9yV9YS_",
    "outputId": "7cce6f1a-291b-4227-b51a-cc3805519cf2"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Identify a list of emotions that the writer of the \\\n",
    "following review is expressing. Include no more than \\\n",
    "five items in the list. Format your answer as a list of \\\n",
    "lower-case words separated by commas.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TbEYHE5U9uDp"
   },
   "source": [
    "### Anger detection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8ZH_Y279msV",
    "outputId": "04ecc57c-23d3-4dbf-e1aa-4f12f1a8f67b"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Is the writer of the following review expressing anger?\\\n",
    "The review is delimited with triple backticks. \\\n",
    "Give your answer as either yes or no.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TkyWozv295Lk"
   },
   "source": [
    "### Extract entities\n",
    "\n",
    "Scope:\n",
    "\n",
    "- Extraction of product names and company names"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkS0nf2e9zn3",
    "outputId": "6aa43a9e-a2e2-4e1e-9acd-9addce099466"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRm3sFns-L4p"
   },
   "source": [
    "### Solving multiple tasks at once\n",
    "\n",
    "Scope:\n",
    "\n",
    "- Sentiment analysis\n",
    "- Anger detection\n",
    "- Extraction of entities: product and company names"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8O8ezx04-D0S",
    "outputId": "bf68532a-ff72-4fa1-9103-a2efb747c77a"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Identify the following items from the review text:\n",
    "- Sentiment (positive or negative)\n",
    "- Is the reviewer expressing anger? (true or false)\n",
    "- Item purchased by reviewer\n",
    "- Company that made the item\n",
    "\n",
    "The review is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Sentiment\", \"Anger\", \"Item\" and \"Brand\" as the keys.\n",
    "If the information isn't present, use \"unknown\" \\\n",
    "as the value.\n",
    "Make your response as short as possible.\n",
    "Format the Anger value as a boolean.\n",
    "\n",
    "Review text: '''{lamp_review}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7I98rHb-mNN"
   },
   "source": [
    "### Topic detection (open)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f634YFOT-p73"
   },
   "source": [
    "story = \"\"\"\n",
    "In a recent survey conducted by the government,\n",
    "public sector employees were asked to rate their level\n",
    "of satisfaction with the department they work at.\n",
    "The results revealed that NASA was the most popular\n",
    "department with a satisfaction rating of 95%.\n",
    "\n",
    "One NASA employee, John Smith, commented on the findings,\n",
    "stating, \"I'm not surprised that NASA came out on top.\n",
    "It's a great place to work with amazing people and\n",
    "incredible opportunities. I'm proud to be a part of\n",
    "such an innovative organization.\"\n",
    "\n",
    "The results were also welcomed by NASA's management team,\n",
    "with Director Tom Johnson stating, \"We are thrilled to\n",
    "hear that our employees are satisfied with their work at NASA.\n",
    "We have a talented and dedicated team who work tirelessly\n",
    "to achieve our goals, and it's fantastic to see that their\n",
    "hard work is paying off.\"\n",
    "\n",
    "The survey also revealed that the\n",
    "Social Security Administration had the lowest satisfaction\n",
    "rating, with only 45% of employees indicating they were\n",
    "satisfied with their job. The government has pledged to\n",
    "address the concerns raised by employees in the survey and\n",
    "work towards improving job satisfaction across all departments.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wBAsH8c5-tDN",
    "outputId": "103bdefe-0801-483f-dca7-77d27ca93f61"
   },
   "source": [
    "# infer 5 topics\n",
    "prompt = f\"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long.\n",
    "\n",
    "Format your response as a list of items separated by commas.\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1tUr85DC_Ejs"
   },
   "source": [
    "### Topic detection from a pre-defined list of topics"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JOTXckhI-1Dy"
   },
   "source": [
    "topic_list = [\n",
    "    \"nasa\",\n",
    "    \"local government\",\n",
    "    \"engineering\",\n",
    "    \"employee satisfaction\",\n",
    "    \"federal government\",\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qyEoLUI6_UyO",
    "outputId": "999c3ded-dcd0-4191-86ef-87bc540a54f3"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Give your answer as list with 0 or 1 for each topic.\\\n",
    "\n",
    "List of topics: {\", \".join(topic_list)}\n",
    "\n",
    "Text sample: '''{story}'''\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiDDFukA_9Dv"
   },
   "source": "### Time to practice on your own"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Task 1: Extract all persons and organizations:"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text = \"\"\"At a recent symposium on emerging health technologies, Dr. Samantha Ellis\n",
    "presented findings from her latest study on AI-assisted diagnostics. Her work, conducted in\n",
    "partnership with Brightwell Institute, emphasized the ethical risks of deploying machine\n",
    "learning in clinical settings without proper oversight.\n",
    "\n",
    "Joining her on the expert panel was Michael Alvarez, a data scientist with a background in public\n",
    "health analytics, and Dr. Lena Fischer, currently leading a behavioral health initiative at WellPath\n",
    "Research Group. Together, they highlighted the need for stronger collaboration between engineers\n",
    "clinicians, and regulatory bodies.\n",
    "\n",
    "The discussion concluded with a call to action for governments and research institutions to create more\n",
    "transparent frameworks to guide the development of medical technologies.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Write your prompt and code here",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Task 2: Identify which of these twitter messages contain adverse drug effects"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "text_1 = \"Took the new migraine med last night. Headache gone, but woke up super dizzy and had to lie down again. Might need to lower the dose? ü§î\"\n",
    "\n",
    "text_2 = \"Started the new allergy pills and finally slept through the night. First time in weeks I‚Äôve been able to breathe without wheezing! üôå\"\n",
    "\n",
    "text_3 = \"Third day on these antibiotics and my stomach is staging a full rebellion. Not sure what's worse ‚Äî the infection or this constant nausea.\"\n",
    "\n",
    "text_4 = \"On day 5 of the new meds. Energy‚Äôs back, appetite‚Äôs good, and the brain fog‚Äôs finally lifting. Feeling more like myself again.\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# Write your prompt and code here",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Task 3: Define your own classification task and write an example for it"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23b86KB3DAGe"
   },
   "source": [
    "## 4. Translation\n",
    "\n",
    "ChatGPT has been trained with multilingual data. For this reason, this model is capable if translating text as well."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YJMPKPvz_1pO"
   },
   "source": [
    "text = \"\"\"\n",
    "Barcelona is a city on the northeastern coast of Spain. \\\n",
    "It is the capital and largest city of the autonomous community of Catalonia, \\\n",
    "as well as the second-most populous municipality of Spain. \\\n",
    "With a population of 1.6 million within city limits, \\\n",
    "its urban area extends to numerous neighbouring municipalities within the province \\\n",
    "of Barcelona and is home to around 4.8 million people, \\\n",
    "making it the fifth most populous urban area in the European Union after Paris, \\\n",
    "the Ruhr area, Madrid and Milan. \\\n",
    "It is one of the largest metropolises on the Mediterranean Sea, \\\n",
    "located on the coast between the mouths of the rivers Llobregat and Bes√≤s, \\\n",
    "bounded to the west by the Serra de Collserola mountain range.\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZySxcDetEVDp",
    "outputId": "222a6835-185a-4c33-9a1d-4357921ad565"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text delimited by tags <text> to Spanish. \\\n",
    "\n",
    "<text>{text}<text>\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXXtutSqEvpn"
   },
   "source": [
    "### Language detection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HwZsP2mEoFC",
    "outputId": "c0396988-376b-4ab6-d874-bcbf4b287144"
   },
   "source": [
    "prompt = \"\"\"\n",
    "Tell me the language of the following text delimited by tags <text>. \\\n",
    "\n",
    "<text>\n",
    "Barcelone est une ville situ√©e sur la c√¥te nord-est de l'Espagne. \\\n",
    "C'est la capitale et la plus grande ville de la communaut√© autonome de Catalogne, \\\n",
    "ainsi que la deuxi√®me municipalit√© la plus peupl√©e d'Espagne. \\\n",
    "Avec une population de 1,6 million d'habitants dans les limites de la ville, \\\n",
    "son aire urbaine s'√©tend √† de nombreuses municipalit√©s voisines de la province \\\n",
    "de Barcelone et abrite environ 4,8 millions de personnes, \\\n",
    "ce qui en fait la cinqui√®me aire urbaine la plus peupl√©e de l'Union europ√©enne \\\n",
    "apr√®s Paris, la r√©gion de la Ruhr, Madrid et Milan. \\\n",
    "C'est l'une des plus grandes m√©tropoles de la mer M√©diterran√©e, \\\n",
    "situ√©e sur la c√¥te entre les embouchures des rivi√®res Llobregat et Bes√≤s, \\\n",
    "bord√©e √† l'ouest par la cha√Æne de montagnes de la Serra de Collserola.\n",
    "<text>\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6IlFSeGBFilk"
   },
   "source": [
    "### Multilingual translation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P4uzHFucFVn4",
    "outputId": "66995351-ce66-4f4a-ff74-1c59814c6ffa"
   },
   "source": [
    "prompt = f\"\"\"\n",
    "Translate the following English text delimited by tags <text> to Spanish and French. \\\n",
    "\n",
    "<text>{text}<text>\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pL5EluMyGZ8W"
   },
   "source": [
    "### Language detection + multilingual translation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9QM2acIsGeod"
   },
   "source": [
    "user_messages = [\n",
    "    \"La performance du syst√®me est plus lente que d'habitude.\",  # System performance is slower than normal\n",
    "    \"Mi monitor tiene p√≠xeles que no se iluminan.\",  # My monitor has pixels that are not lighting\n",
    "    \"Il mio mouse non funziona\",  # My mouse is not working\n",
    "    \"M√≥j klawisz Ctrl jest zepsuty\",  # My keyboard has a broken control key\n",
    "    \"ÊàëÁöÑÂ±èÂπïÂú®Èó™ÁÉÅ\",  # My screen is flashing\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ySqWvpzYGfph",
    "outputId": "3699208f-1761-472d-e259-59d97bc8cc9c"
   },
   "source": [
    "for issue in user_messages:\n",
    "    prompt = f\"Tell me what language this is: ```{issue}```\"\n",
    "    lang = get_completion(prompt)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Translate the following  text to English \\\n",
    "    and Korean: ```{issue}```\n",
    "    \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    render_markdown(f\"**Original message** ({lang}): {issue}\\n{response}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ECZ_wGmGrpn"
   },
   "source": [
    "### Adapt tone of the text"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hYuHubKnGie8",
    "outputId": "d68a2213-2d7f-4e64-878e-7d3dff071724"
   },
   "source": [
    "prompt = \"\"\"\n",
    "Translate the following from slang to a business letter:\n",
    "'Dude, This is Joe, check out this spec on this standing lamp.'\n",
    "\"\"\"\n",
    "show_completion(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jBLQ7pXdHTwz"
   },
   "source": [
    "### Spellcheck and grammar check"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PB3BXnGcHF4J",
    "outputId": "0fa39821-25aa-4220-e645-e52fd23d5559"
   },
   "source": [
    "texts = [\n",
    "    \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
    "    \"Yolanda has her notebook.\",  # ok\n",
    "    \"Its going to be a long day. Does the car need it's oil changed?\",  # Homonyms\n",
    "    \"Their goes my freedom. There going to bring they're suitcases.\",  # Homonyms\n",
    "    \"Your going to need you're notebook.\",  # Homonyms\n",
    "    \"That medicine effects my ability to sleep. Have you heard of the butterfly affect?\",  # Homonyms\n",
    "    \"This phrase is to cherck chatGPT for speling abilitty\",  # spelling\n",
    "]\n",
    "\n",
    "for text in texts:\n",
    "    prompt = f\"\"\"Proofread and correct the following text\n",
    "  and rewrite the corrected version. If you don't find\n",
    "  and errors, just say \"No errors found\". Don't use\n",
    "  any punctuation around the text:\n",
    "  ```{text}```\n",
    "\n",
    "  \"\"\"\n",
    "    response = get_completion(prompt)\n",
    "    render_markdown(f\"## Original text\\n{text}\\n## Corrected text\\n{response}\\n\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLzj2dgkJWdW"
   },
   "source": [
    "As you can see, answers generated are not highly accurate."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
