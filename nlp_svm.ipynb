{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/martatolos/eae-dsaa-2025/blob/main/nlp_svm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "id": "279d0aa1e768b674"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Natural Language Processing (NLP) - Part I\n",
    "\n",
    "Goal of the session:\n",
    "\n",
    "Implement essential pipeline to process and classify documents using `nltk`, `scikit-learn` and `fastembed`."
   ],
   "id": "c0a7bce68ac52ab2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prerequisites\n",
    "\n",
    "First, let's install all necessary requirements"
   ],
   "id": "6a03f32474a86c44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Install requirements\n",
    "%pip install numpy==2.0.2 pandas==2.2.2 scikit-learn==1.6.1 seaborn==0.13.2 fastembed==0.7.0 nltk==3.9.1"
   ],
   "id": "7f1a304c5bc77ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from typing import Iterable\n",
    "\n",
    "# Install necessary nltk packages\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "\n",
    "EN_STOP_WORDS = {word: True for word in stopwords.words('english')}"
   ],
   "id": "23d9f44c1da0fb67",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Read and Inspect the Data\n",
    "\n",
    "In this tutorial we will leverage a dataset that contains movie reviews rated as positive or negative."
   ],
   "id": "42bb2ecc8f0d7b24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T22:04:32.270982Z",
     "start_time": "2025-05-19T22:04:32.259594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_url = \"https://raw.githubusercontent.com/martatolos/eae-dsaa-2025/refs/heads/main/reviews.tsv\"\n",
    "data = pd.read_csv(data_url, sep=\"\\t\", names=[\"review_id\", \"label\", \"text\"], nrows=300, index_col=\"review_id\")\n",
    "data"
   ],
   "id": "5d3b9852eda7d21c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          label                                               text\n",
       "review_id                                                         \n",
       "0           pos  You know, Robin Williams, God bless him, is co...\n",
       "1           pos  I thought it was a pretty good movie and shoul...\n",
       "2           neg  tries to be funny and fails miserably. The ani...\n",
       "3           neg  As long as there's been 3d technology, (1950's...\n",
       "4           neg  The characters are cliched and predictable, wi...\n",
       "...         ...                                                ...\n",
       "295         neg  I enjoyed the feel of the opening few minutes,...\n",
       "296         neg  I was aware of Rohmer's admiration for the lat...\n",
       "297         neg  A Movie about a bunch of some kind of filmmake...\n",
       "298         pos  Matthau and Lemmon are at their very best in t...\n",
       "299         pos  This was a very well scripted movie. Great fun...\n",
       "\n",
       "[300 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pos</td>\n",
       "      <td>You know, Robin Williams, God bless him, is co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pos</td>\n",
       "      <td>I thought it was a pretty good movie and shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>tries to be funny and fails miserably. The ani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>As long as there's been 3d technology, (1950's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>The characters are cliched and predictable, wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>neg</td>\n",
       "      <td>I enjoyed the feel of the opening few minutes,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>neg</td>\n",
       "      <td>I was aware of Rohmer's admiration for the lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>neg</td>\n",
       "      <td>A Movie about a bunch of some kind of filmmake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>pos</td>\n",
       "      <td>Matthau and Lemmon are at their very best in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>pos</td>\n",
       "      <td>This was a very well scripted movie. Great fun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The text originate from a website, so we have some markup language (e.g., `<br />` for line break) in the text.",
   "id": "5022897ee2db36fe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data[\"text\"] = data[\"text\"].apply(lambda x: x.replace(\"<br />\", \" \"))",
   "id": "646476335d1551d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's inspect the label distribution of the data set",
   "id": "4c69e057e1109d74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Output label distribution\n",
    "data[\"label\"].value_counts()"
   ],
   "id": "115e9397b6ed60b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Print class ratios\n",
    "data[\"label\"].value_counts(normalize=True)"
   ],
   "id": "514f271d761097fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Investigate the most frequent words for each label.",
   "id": "d29e4a2256201148"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_word_frequencies(texts: Iterable[str]) -> Counter:\n",
    "    \"\"\" Get word frequency map.\n",
    "\n",
    "    :param texts: List of texts to be investigated\n",
    "    :return: Counter object of word frequencies\n",
    "    \"\"\"\n",
    "    # Concatenate all texts\n",
    "    complete_text = \" \".join(texts)\n",
    "\n",
    "    # Tokenize the text in single words\n",
    "    words = nltk.word_tokenize(complete_text)\n",
    "\n",
    "    # Remove stop words and non-alphabetic words\n",
    "    words = [word for word in words if word.isalpha() and word not in EN_STOP_WORDS]\n",
    "\n",
    "    return Counter(words)\n"
   ],
   "id": "620c557be2da4209",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_pos_words = get_word_frequencies(data[data[\"label\"] == \"pos\"][\"text\"])\n",
    "print(top_pos_words.most_common(20))"
   ],
   "id": "7ba79e9791306589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "top_neg_words = get_word_frequencies(data[data[\"label\"] == \"neg\"][\"text\"])\n",
    "print(top_neg_words.most_common(20))"
   ],
   "id": "443ae98ec97d32d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train a document classifier\n",
    "\n",
    "1. First we have to transform our string labels (i.e. \"pos\" and \"neg\") to indices (i.e, 0 and 1). This can be done using the `LabelEncoder` from the `scikit-learn` library."
   ],
   "id": "c87074bbb31482d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "encoded_labels = encoder.fit_transform(data[\"label\"])"
   ],
   "id": "ab81b4b9b11ffe5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Inspect the original and encoded labels of the first 5 reviews\n",
    "print(\"Original labels:\", data[\"label\"].head(5))\n",
    "print(\"Encoded labels:\", encoded_labels[:5])"
   ],
   "id": "5c6511ca7dab8b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# The encoder stores the mapping between the class labels and the indices internally\n",
    "print(encoder.classes_)\n",
    "\n",
    "# This information can be used to easily transform between class labels and indices and vice versa\n",
    "print(encoder.transform([\"pos\", \"pos\"]))\n",
    "print(encoder.inverse_transform([0, 0, 1]))"
   ],
   "id": "1f041772f5df028f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2. Split the dataset into train and test",
   "id": "6e03cd96c7b6e8c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Split our dataset into train and test subset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[\"text\"], encoded_labels, test_size=0.3, random_state=70, stratify=encoded_labels)"
   ],
   "id": "ac9639ed1eb6b24d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "X_train",
   "id": "7794adfe9dbd085d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "y_train",
   "id": "99f1312439f4ae74",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Transform the texts into feature vectors",
   "id": "45f83228b235d19d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    ngram_range=(2, 2),\n",
    "    max_df=0.90,     # ignore terms that occur in >90% of documents\n",
    "    min_df=2,        # ignore terms in <2 documents\n",
    "    stop_words=list(EN_STOP_WORDS.keys()),  # or \"english\"\n",
    "\n",
    "    #  Use binary=True when presence of a word is more important than its frequency\n",
    "    # binary=True\n",
    ")\n",
    "\n",
    "# Fit and transform the documents\n",
    "tfidf_train = vectorizer.fit_transform(X_train)\n",
    "tfidf_train"
   ],
   "id": "a6ba272875179920",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Convert to DataFrame for readability (optional)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "df_tfidf_train = pd.DataFrame(tfidf_train.toarray(), columns=feature_names)\n",
    "\n",
    "df_tfidf_train"
   ],
   "id": "bb6e29207cf9cf3e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Train a classification model",
   "id": "d171e33412ab2805"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the classifier with the dense features\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf_nb = MultinomialNB()\n",
    "clf_nb.fit(tfidf_train, y_train)"
   ],
   "id": "b53c04602d671160",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "5. Evaluate the classifier",
   "id": "9de6fd4de991728a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Transform the test texts into feature vectors\n",
    "tfidf_test = vectorizer.transform(X_test)\n",
    "\n",
    "y_pred = clf_nb.predict(tfidf_test)\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))"
   ],
   "id": "a1d36fc6c272cabe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise: Investigate different options for text preprocessing and classification models\n",
    "\n",
    "Experiment with different options, e.g.:\n",
    "- Investigate different parameter options for the TF-IDF vectorizer\n",
    "- Test different classification models (e.g., LogisticRegression, SVM, ...)"
   ],
   "id": "ff30c2846feff568"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add you code here\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "e30e781c87fd3aaf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Use Dense Embeddings for Text Encoding\n",
    "\n",
    "In the example above we used traditional statistical text encoding methods generating sparse, high-dimensional feature vectors. In the following cells, we'll use a text encoding model producing dense, low-dimensional embeddings instead. For this, we'll use the `fastembed` library and the `BAAI/bge-small-en-v1.5` language model (33.4 million parameters)."
   ],
   "id": "6a9db11396bccb63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from fastembed import TextEmbedding\n",
    "\n",
    "model = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "# This will trigger the model download and initialization\n",
    "embedding_model = TextEmbedding(model_name=model)\n",
    "print(f\"The model {model} is ready to use.\")"
   ],
   "id": "aa8a3450ac669373",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Encode the texts\n",
    "embeddings_train = list(embedding_model.embed(X_train))"
   ],
   "id": "e0b9664a3bd542bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prints the vector for the first data point\n",
    "print(embeddings_train[0])\n",
    "\n",
    "# Prints the size of the vector\n",
    "print(embeddings_train[0].shape)"
   ],
   "id": "b616a41330417a4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Retrain the classifier",
   "id": "e90bad5df3f7705b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train the classifier with the dense features\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lg = LogisticRegression()\n",
    "clf_lg.fit(embeddings_train, y_train)"
   ],
   "id": "69bcea96442581cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Encode test texts\n",
    "embeddings_test = list(embedding_model.embed(X_test))"
   ],
   "id": "232d41424f6f779d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the classifier\n",
    "y_pred = clf_lg.predict(embeddings_test)\n",
    "print(classification_report(y_test, y_pred, target_names=encoder.classes_))"
   ],
   "id": "c8fc6fcbb1e340b7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exercise: Test your own classifier\n",
    "\n",
    "Test the classifiers that you investigated in the previous exercise now with the dense embedding. Which changes can be recognized."
   ],
   "id": "2e094720c62cbec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add your code\n",
    "\n"
   ],
   "id": "390ce9585522b4bd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
